{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Airborne Detection Benchmark: EFS example",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VuongTuanKhanh/Funix-Capstone-Project/blob/main/notebooks/EFS_and_S3FS_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVBdVBfLY32H"
      },
      "source": [
        "# How to access dataset using EFS?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DenOF4IMMle",
        "outputId": "eaed63e3-c223-41cb-b7c6-93c9dc93cb11"
      },
      "source": [
        "!apt install nfs-common tree"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tree is already the newest version (1.7.0-5).\n",
            "nfs-common is already the newest version (1:1.3.4-2.1ubuntu5.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLyW3RgaVIAC"
      },
      "source": [
        "!mkdir -p data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfEAjjn3VLTq"
      },
      "source": [
        "!sudo mount -t nfs -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2 airborne-object-tracking-dataset.aicrowd.com:/ data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8OeQQCLVwO8",
        "outputId": "8ae1e3ee-d6ba-4018-a9ea-3fdee429dcbc"
      },
      "source": [
        "!tree -L 3 data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data/\n",
            "└── aot_training\n",
            "    ├── annotation\n",
            "    │   ├── anno\n",
            "    │   ├── anno.json\n",
            "    │   └── splits.json\n",
            "    └── raw_data\n",
            "        ├── train1\n",
            "        ├── train2\n",
            "        └── train3\n",
            "\n",
            "7 directories, 2 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmTB1ho8a4fg"
      },
      "source": [
        "# How to access dataset using s3fs?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SDNSclXa4f4",
        "outputId": "26add622-f9ad-4fa7-ff26-dd32c08199d7"
      },
      "source": [
        "!apt install s3fs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  s3fs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 200 kB of archives.\n",
            "After this operation, 557 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 s3fs amd64 1.82-1 [200 kB]\n",
            "Fetched 200 kB in 1s (285 kB/s)\n",
            "Selecting previously unselected package s3fs.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../archives/s3fs_1.82-1_amd64.deb ...\n",
            "Unpacking s3fs (1.82-1) ...\n",
            "Setting up s3fs (1.82-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOxsP6Q2a4f6"
      },
      "source": [
        "!mkdir data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM7pgdQTa4f7"
      },
      "source": [
        "!s3fs airborne-obj-detection-challenge-training data/ -o public_bucket=1,ro"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OG4BEuUa4f7",
        "outputId": "4dfe3609-2b14-4822-f3ff-ea910d8fc4e7"
      },
      "source": [
        "!ls data/*"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data/part1:\n",
            "Images\tImageSets\n",
            "\n",
            "data/part2:\n",
            "Images\tImageSets\n",
            "\n",
            "data/part3:\n",
            "Images\tImageSets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3piYz-pPV4Tj"
      },
      "source": [
        "## REMINDER\n",
        "\n",
        "Listing of files via s3fs is slow, because metadata operations in s3 are slow.\n",
        "\n",
        "Best way to utilise s3fs is download or read the `groundtruth.json` file and then read all the relevant files using full path.\n"
      ]
    }
  ]
}